# -*- coding: utf-8 -*-

# Roger - Facial detection
# Joseph - Canny
# Lyndon - Canny line -> smoothing/thickness modifier along lines
# Sabrina - Textures
# Kelsey - Quantizing RGB/HSV


"""CS4476Prj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WGs55cY6plbmUJFE-gipBV8MQNJsHIBL

<center>
    <h1>CS  4476: Fall 2020</h1>
    <h1>Final Project</h1>
    <h3>Sabrina Chua, Kelsey Henson, Joseph Lee, Roger Nhan, Lyndon Puzon
 </h3>
</center>
"""

#export
from matplotlib import use
import numpy as np

np.set_printoptions(threshold=np.inf)
from sklearn.cluster import KMeans
from skimage.color import rgb2hsv, hsv2rgb, rgb2gray, rgba2rgb
from skimage import feature, color, draw
from imageio import imread, imsave
from scipy import ndimage
from typing import Tuple, overload
from PIL import Image
from edgeDetection import edgeDetection, edgeDetailDetection
from matplotlib import pyplot as plt
from texture import median_filter, FillColors
from binary_skin import binary_skin_erosion_dilation


#export
def quantize_hsv(img: np.ndarray, k: int):
    """
    Compute the k-means clusters for the input image in the hue dimension of the
    HSV space. Replace the hue values with the nearest cluster's hue value. Finally,
    convert the image back to RGB.
    
    Inputs:
        img: Input RGB image with shape H x W x 3 and dtype "uint8"
        k: The number of clusters to use

    Output:
        An RGB image with shape H x W x 3 and dtype "uint8"
    """
    quantized_img = np.zeros_like(img)

    ##########################################################################
    # TODO: Convert the image to HSV. Perform k-means clustering in hue      #
    # space. Replace the hue values in the image with the cluster centers.   #
    # Convert the image back to RGB.                                         #
    ##########################################################################
    
    #Converting image to HSV and retrieving H channels
    image = rgb2hsv(img)
    h,w,_ = image.shape
    hue = image[:,:,0]
    hue = hue.reshape(h*w,1)

    clusters = KMeans(n_clusters=k, random_state=101)
    kmeans = clusters.fit(hue)
    labels = kmeans.predict(hue)

    colors = np.array(kmeans.cluster_centers_)

 
    for row in range(0,len(hue)):
        hue[row] = colors[labels[row]]
    
    hue = hue.reshape(image[:,:,0].shape)

    quantized_img = np.copy(image)
    quantized_img[:,:,0] = hue

    quantized_img = hsv2rgb(quantized_img)
    quantized_img = quantized_img * 255
    quantized_img = quantized_img.astype(np.uint8)
    



    ##########################################################################
    ##########################################################################

    return quantized_img

# Quantize RGB
#export
def quantize_rgb(img: np.ndarray, k: int):
    """
    Compute the k-means clusters for the input image in RGB space, and return
    an image where each pixel is replaced by the nearest cluster's average RGB
    value.

    Inputs:
        img: Input RGB image with shape H x W x 3 and dtype "uint8"
        k: The number of clusters to use

    Output:
        An RGB image with shape H x W x 3 and dtype "uint8"
    """
    quantized_img = np.zeros_like(img)
    

    ##########################################################################
    # TODO: Perform k-means clustering and return an image where each pixel  #
    # is assigned the value of the nearest clusters RGB values.              #
    ##########################################################################
 
    x, y, z = img.shape
    listImg = img.reshape(x*y, z)

    kmeans = KMeans(n_clusters=k, random_state=101).fit(listImg)
    
    # centers = kmeans.cluster_centers_.astype(int)
    print(kmeans.cluster_centers_.shape)
    # kmeans.cluster_centers_ = np.vstack((kmeans.cluster_centers_, np.array([[0, 0, 0]])))
    labels = kmeans.predict(listImg)
    print(kmeans.cluster_centers_.shape)
    return kmeans.cluster_centers_.astype(int)[labels].reshape(x, y, z)

    ##########################################################################
    ##########################################################################
    
    return quantized_img

original = imread("../res/images/person2.jpg")

if original.shape[2] == 4:
    original = rgba2rgb(original).astype(np.uint8)

# img_quantize = quantize_rgb(original, k=8)
face_mask = binary_skin_erosion_dilation(original)
original_hsv = rgb2hsv(original)
if np.max(face_mask) != 0:
    skin_avgR = np.average(original_hsv[:,:,0], weights=face_mask)
    skin_avgG = np.average(original_hsv[:,:,1], weights=face_mask)
    skin_avgB = np.average(original_hsv[:,:,2], weights=face_mask)
    hsvArr = np.array([skin_avgR, skin_avgG, skin_avgB])
    rgbArr = (hsv2rgb(hsvArr) * 255).astype(np.uint8)
    print(rgbArr)

# face_mask = np.zeros_like(original[:, :, 0])
img_quantize = median_filter(FillColors(np.copy(original), 15, face_mask).get_img())
# img_quantize = original
img_quantize_face = quantize_rgb(original, k=3)

edges = edgeDetection(img_quantize)
edgesDetail = edgeDetailDetection(original)
edges_face = edgeDetection(img_quantize_face, 2)

overlaid_img = np.copy(img_quantize).astype(np.float32)
if np.max(face_mask) != 0:
    overlaid_img[face_mask == 1] = rgbArr
overlaid_img[np.logical_and(edges, np.logical_not(face_mask))] = 0
overlaid_img[np.logical_and(edgesDetail, np.logical_not(face_mask))] *= 0.5
overlaid_img[np.logical_and(edges_face, face_mask)] *= 0.9
overlaid_img = overlaid_img.astype(np.uint8)
# overlaid_img[edges] = 0

# fig, axs = plt.subplots(2, 3, figsize=(15,15))

# axs[0, 0].imshow(original)
# axs[0, 1].imshow(face_mask, cmap="gray")
# axs[0, 2].imshow(edges, cmap="gray")
# axs[1, 0].imshow(edges_face, cmap="gray")
# axs[1, 1].imshow(overlaid_img)

fig, axs = plt.subplots(1, 2)

axs[0].imshow(original)
axs[1].imshow(face_mask, cmap="gray")

plt.show()
# Smooth/reinforce lines

# Textures
# img_array = imread('hill.jpg')

# fig = plt.figure()
# axes = plt.axes()

# temp = texture.FillColors(img_array, 15)
# image = temp.get_img()
# fitered = texture.median_filter(img_array)

# axes.imshow(fitered)
# plt.show()

#test2

# Blob detection

